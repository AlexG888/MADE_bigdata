{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Tokenizer, HashingTF, IDF, StopWordsRemover, StringIndexer, Word2Vec\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = (SparkSession.builder\n",
    "        .appName('Toxic Comment Classification')\n",
    "        .config(\"spark.executor.memory\", \"1G\")\n",
    "        .config(\"spark.driver.memory\",\"2G\")\n",
    "        .config(\"spark.executor.cores\",\"7\")\n",
    "        .config(\"spark.python.worker.memory\",\"1G\")\n",
    "        .config(\"spark.default.parallelism\",\"4\")\n",
    "        .getOrCreate())\n",
    "ss.sparkContext.setLogLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(file):\n",
    "    df = pd.read_csv(f'data/{file}.csv')\n",
    "    return ss.createDataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashingTF_idf(data):\n",
    "    tokenizer = Tokenizer(inputCol=\"comment_text\", outputCol=\"words\")\n",
    "    wordsData = tokenizer.transform(data)\n",
    "\n",
    "    hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\")\n",
    "    tf = hashingTF.transform(wordsData)\n",
    "    hashingTF.setNumFeatures(1024)\n",
    "\n",
    "    idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "    idf_model = idf.fit(tf) \n",
    "    return idf_model.transform(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec(data):\n",
    "    tokenizer = Tokenizer(inputCol=\"comment_text\", outputCol=\"words\")\n",
    "    words_data = tokenizer.transform(data)\n",
    "\n",
    "    w2v = Word2Vec(vectorSize=100, inputCol=\"words\", outputCol=\"features\")\n",
    "    w2v_model = w2v.fit(words_data) \n",
    "    return w2v_model.transform(words_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_evaluation(data, cols):\n",
    "    eval_dict = {}\n",
    "    for col in cols: \n",
    "        evaluation = BinaryClassificationEvaluator(rawPredictionCol=f\"{col}_prediction\", labelCol=col, metricName='areaUnderROC')\n",
    "        eval_dict[col] = evaluation.evaluate(data)\n",
    "    return eval_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_model(train,test,marks):\n",
    "    test_res = test.select('id')\n",
    "    out_cols = [i for i in train.columns if i not in [\"id\", \"comment_text\", \"words\", \"rawFeatures\", \"features\"]]\n",
    "    extract_prob = F.udf(lambda x: float(x[1]), T.FloatType())\n",
    "\n",
    "    test_probs = []\n",
    "    for col in out_cols:\n",
    "        lr = LogisticRegression(featuresCol=\"features\", labelCol=col, regParam=0.05)\n",
    "        paramGrid = (ParamGridBuilder().addGrid(lr.regParam, [0.05, 0.1, 0.3]).build())\n",
    "        cv = CrossValidator(estimator=lr,\n",
    "                            estimatorParamMaps=paramGrid,\n",
    "                            evaluator=BinaryClassificationEvaluator(rawPredictionCol=\"prediction\", labelCol=col, metricName='areaUnderROC'),\n",
    "                            numFolds=2)\n",
    "        cl_lr_model = cv.fit(train)\n",
    "        res = cl_lr_model.transform(test)\n",
    "        test_res = test_res.join(res.select('id', 'prediction'), on=\"id\")\n",
    "        test_res = test_res.withColumnRenamed('prediction', f\"{col}_prediction\")\n",
    "\n",
    "    res_for_test = test_res.join(marks, on=\"id\")\n",
    "    print(_get_evaluation(res_for_test, out_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'toxic': 0.6266565141060169, 'severe_toxic': 0.7326115809402718, 'obscene': 0.6604303087240774, 'threat': 0.6624006455250596, 'insult': 0.6737980158686908, 'identity_hate': 0.6929353462580896}\n"
     ]
    }
   ],
   "source": [
    "train = prep_data('train')\n",
    "train = train.withColumn(\"toxic\",train.toxic.cast('int'))\n",
    "train = train.withColumn(\"severe_toxic\",train.toxic.cast('int'))\n",
    "train = train.withColumn(\"obscene\",train.toxic.cast('int'))\n",
    "train = train.withColumn(\"threat\",train.toxic.cast('int'))\n",
    "train = train.withColumn(\"insult\",train.toxic.cast('int'))\n",
    "train = train.withColumn(\"identity_hate\",train.toxic.cast('int'))\n",
    "\n",
    "test = prep_data('test')\n",
    "marks = prep_data('marks')\n",
    "\n",
    "train_data = hashingTF_idf(train)\n",
    "test_data = hashingTF_idf(test)\n",
    "learn_model(train_data, test_data, marks) # numFeatures=1048576"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'toxic': 0.6266565141060169, 'severe_toxic': 0.7326115809402718, 'obscene': 0.6604303087240774, 'threat': 0.6624006455250596, 'insult': 0.6737980158686908, 'identity_hate': 0.6929353462580896}\n"
     ]
    }
   ],
   "source": [
    "train_data = hashingTF_idf(train)\n",
    "test_data = hashingTF_idf(test)\n",
    "learn_model(train_data, test_data, marks) # numFeatures=1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'toxic': 0.5717122309532192, 'severe_toxic': 0.6977031348897644, 'obscene': 0.6112809898418207, 'threat': 0.635977357018018, 'insult': 0.5998972935547053, 'identity_hate': 0.5892826276342719}\n"
     ]
    }
   ],
   "source": [
    "train_data = word2vec(train)\n",
    "test_data = word2vec(test)\n",
    "learn_model(train_data, test_data, marks)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы\n",
    "\n",
    "По умолчанию значение NumFeatures 1048576, попробовал установить 1024(так как почитал, что рекомендуется использовать степени двойки), но не получил никакой разницы.\n",
    "\n",
    "HashingTF_idf лучше справляется с постаеленной задачей чем word2vec."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Oct 13 2022, 10:17:43) [Clang 14.0.0 (clang-1400.0.29.102)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
